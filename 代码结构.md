> 我再也不搞merge了因为auto-merge真的把我当傻子

# train
## usage
1. 纯服务器调用：上传数据集后，在服务器端运行`CUDA_VISIBLE_DEVICES=2 HF_HUB_OFFLINE=1 python lerobot/scripts/train.py --config_path=simplify_work/work/train/xxx.yaml`
2. 参数 configs/train.py里面，加了三个
```python
    """
    为了在多模态里面选择用/不用depth_image，默认为false。scripts/train.py
    """
    use_depth_image: bool=False
    use_force: bool=False
    use_language_tip: bool=False
```

## modified
scripts/train.py里面

1. 修改tokenizer和multi gpu bug,os的指定改到命令行里面了

```python
# https://github.com/huggingface/lerobot/issues/1377
import os
# os.environ["CUDA_VISIBLE_DEVICES"] = "1"
os.environ["TOKENIZERS_PARALLELISM"] = "false"
```
2. 根据config的3个变量，filter batch的内容，因为原始数据集里面feature比较多

```python
class FilteredBatchLoader:
    def __init__(self, dataloader, exclude_keys: list):
        self.dataloader = dataloader
        self.exclude_keys = set(exclude_keys)

    def __iter__(self):
        for batch in self.dataloader:
            yield {
                k: v for k, v in batch.items() if k not in self.exclude_keys
            }

    def __len__(self):
        return len(self.dataloader)
# ...
# 后面用的时候

    #  构造 exclude list
    exclude_features = []
    if not cfg.use_depth_image:
        exclude_features += ["observation.images.side_depth", "observation.images.side_depth_is_pad"]
    if not cfg.use_force:
        exclude_features += ["observation.force", "observation.force_is_pad"]
    if not cfg.use_language_tip:
        # 加语言引导的
        pass

    #  包装 dataloader
    dataloader = FilteredBatchLoader(raw_dataloader, exclude_features)
    peek_batch = next(iter(dataloader))
    print("真正训练的时候甬道的feature：", list(peek_batch.keys()))

```




## structure
1. update_policy
   1. 真实训练过程
2. train
   1. 用trainpipelineconfig创建train过程，wandb没用了，检查device，load dataset和policy，optimizer和grad等
   2. 调用update_policy
   3. save checkpoint
3. 如果要继续训练的话就要用    if cfg.resume:


# accelerate-train
还没添加。可以参考https://github.com/huggingface/lerobot/pull/1246

# evaluate
## usage
1. 服务器运行 `CUDA_VISIBLE_DEVICES=3 python simplify_work/server/server_code/get_data_from_client.py` cuda_visible可以不加
2. 本地运行 `ENV=local python -m lerobot.record --config_path=simplify_work/work/evaluate_record.yaml` 第一个是用来区分本地和服务器的。

## modified
1. modeling_smolvla.py

区分服务器和本地。本地就调用predict_from_server_api，服务器则是直接用policy.get_action_chunk
```python
IS_LOCAL = os.environ.get("ENV", "") == "local"
print(f"IS_LOCAL = {IS_LOCAL}")
# 如果判断是本地的
if IS_LOCAL:
    # 服务器推理
    import sys

    # 获取该文件所在目录（control_utils.py）
    current_dir = os.path.dirname(os.path.abspath(__file__))

    # 找到 simplify_work/server/local_code 所在目录的绝对路径
    predict_code_dir = os.path.abspath(os.path.join(current_dir, '../../../../../simplify_work/server/local_code'))

    # 临时加入 Python 模块搜索路径
    if predict_code_dir not in sys.path:
        sys.path.insert(0, predict_code_dir)
    from predict_from_server_api import predict_from_server
```
```python
# 开启服务器推理。本地使用这个，并且注释掉后面四行。
        if IS_LOCAL:
            actions=predict_from_server(batch)
        else:
        # 服务器就注释掉上面一行，使用下面四行。

            images, img_masks = self.prepare_images(batch)
            state = self.prepare_state(batch)
            lang_tokens, lang_masks = self.prepare_language(batch)
            actions = self.model.sample_actions(images, img_masks, lang_tokens, lang_masks, state, noise=noise)

```


## structure
1. record.py 一开始调用的，DatasetRecordConfig，RecordConfig，record_loop和record。调用predict_action

```python
action_values = predict_action(
                observation_frame,
                policy,
                get_safe_torch_device(policy.config.device),
                policy.config.use_amp,
                task=single_task,
                robot_type=robot.robot_type,
            )
```

2. control_utils里面的predict_action

```python
action = policy.select_action(observation)
```
3. 